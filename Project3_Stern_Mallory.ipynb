{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "82754162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/mj/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/mj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/mj/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/mj/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /Users/mj/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/mj/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/mj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mj/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/mj/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to /Users/mj/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import re\n",
    "import pdfplumber\n",
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cb0c9f",
   "metadata": {},
   "source": [
    "### 1. Extract all texts from the given pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0858313",
   "metadata": {},
   "outputs": [],
   "source": [
    "riskpdf = \"/Users/mj/Desktop/DSCI 314 (Text Mining)/CAS_ERM_overview.pdf\"\n",
    "\n",
    "# Open and read the PDF\n",
    "with pdfplumber.open(riskpdf) as pdf:\n",
    "    output = []\n",
    "    for page in pdf.pages:\n",
    "        # Extract text from each page\n",
    "        output.append(page.extract_text())\n",
    "        \n",
    "# Concatenate all text\n",
    "alltexts = ' '.join(output)\n",
    "\n",
    "#Lower case the string\n",
    "alltexts = alltexts.lower()\n",
    "# Remove \\n from the texts\n",
    "alltexts = re.sub(r'\\n', '', alltexts)\n",
    "# Remove punctuation from the texts\n",
    "alltexts = re.sub(r'[^\\w\\s]','',alltexts)\n",
    "# Remove number from texts\n",
    "num = r'[0-9]'\n",
    "# Match all digits in the string and replace them by empty string\n",
    "alltexts = re.sub(num , '', alltexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dd2f9e",
   "metadata": {},
   "source": [
    "### 2. Extract all the tokens from the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cab3667a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overview', 'of', 'enterprise', 'risk', 'managementcasualty', 'actuarial', 'societyenterprise', 'risk', 'management', 'committeemay', 'overview', 'of', 'enterprise', 'risk', 'managementtable', 'of', 'contentspagei', 'executive', 'summary', 'ii', 'the', 'erm', 'evolution', 'iii', 'erm', 'definition', 'and', 'conceptual', 'framework', 'iv', 'erm', 'language', 'measures', 'models', 'and', 'tools', 'v', 'erm', 'case', 'studies', 'vi', 'practical', 'considerations', 'in', 'implementing', 'erm', 'appendicesa', 'riskrelated', 'regulatory', 'rating', 'agency', 'and', 'corporate', 'governanceguidelines', 'and', 'requirements', 'b', 'a', 'continuum', 'of', 'risk', 'modeling', 'methods', 'c', 'erm', 'bibliography', 'overview', 'of', 'enterprise', 'risk', 'managementi', 'executive', 'summarythis', 'document', 'is', 'intended', 'primarily', 'to', 'further', 'the', 'risk', 'management', 'education', 'ofcandidates', 'for', 'membership', 'in', 'the', 'casualty', 'actuarial', 'society', 'cas', 'current', 'members', 'ofthe', 'cas', 'as', 'well', 'as', 'other']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize by splitting into words\n",
    "tokens = word_tokenize(alltexts)\n",
    "print(tokens[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a8aea4",
   "metadata": {},
   "source": [
    "### 3. Perform Stemming on the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa277d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "managementi :  managementi\n",
      "management :  manag\n",
      "managementtable :  managementt\n",
      "managementcasualty :  managementcasualti\n"
     ]
    }
   ],
   "source": [
    "# Stemming various words related to management\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "words = [\"managementi\", \"management\", \"managementtable\", \"managementcasualty\"]\n",
    "for stemmedword in words:\n",
    "    print(stemmedword, \": \", stemmer.stem(stemmedword))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02362c41",
   "metadata": {},
   "source": [
    "### 4. Perform Lemmatization on the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7fcd15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "managementi :  managementi\n",
      "management :  management\n",
      "managementtable :  managementtable\n",
      "managementcasualty :  managementcasualty\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize various words related to management\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = [\"managementi\", \"management\", \"managementtable\", \"managementcasualty\"]\n",
    "for lemword in words:\n",
    "    print(lemword, \": \", lemmatizer.lemmatize(lemword))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a94f8",
   "metadata": {},
   "source": [
    "### 5. Remove all the default stop words in NLTK from the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "921eac0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overview', 'enterprise', 'risk', 'managementcasualty', 'actuarial', 'societyenterprise', 'risk', 'management', 'committeemay', 'overview', 'enterprise', 'risk', 'managementtable', 'contentspagei', 'executive', 'summary', 'ii', 'erm', 'evolution', 'iii', 'erm', 'definition', 'conceptual', 'framework', 'iv', 'erm', 'language', 'measures', 'models', 'tools', 'v', 'erm', 'case', 'studies', 'vi', 'practical', 'considerations', 'implementing', 'erm', 'appendicesa', 'riskrelated', 'regulatory', 'rating', 'agency', 'corporate', 'governanceguidelines', 'requirements', 'b', 'continuum', 'risk', 'modeling', 'methods', 'c', 'erm', 'bibliography', 'overview', 'enterprise', 'risk', 'managementi', 'executive', 'summarythis', 'document', 'intended', 'primarily', 'risk', 'management', 'education', 'ofcandidates', 'membership', 'casualty', 'actuarial', 'society', 'cas', 'current', 'members', 'ofthe', 'cas', 'well', 'risk', 'management', 'professionals', 'also', 'find', 'material', 'ofinterestin', 'chapter', 'ii', 'evolution', 'rationale', 'enterprise', 'risk', 'management', 'erm', 'isexplained', 'erm', 'movement', 'driven', 'internal', 'eg', 'competitiveadvantage']\n"
     ]
    }
   ],
   "source": [
    "# Import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# Remove stopwords\n",
    "without_stopword = [w for w in tokens if not w in stop_words]\n",
    "print(without_stopword[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ff5591",
   "metadata": {},
   "source": [
    "### 6. Customize the stop words in NLTK by adding \"language\" and \"processing\" to the stop words and removing \"most\" from the default stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e09dcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overview', 'enterprise', 'risk', 'managementcasualty', 'actuarial', 'societyenterprise', 'risk', 'management', 'committeemay', 'overview', 'enterprise', 'risk', 'managementtable', 'contentspagei', 'executive', 'summary', 'ii', 'erm', 'evolution', 'iii', 'erm', 'definition', 'conceptual', 'framework', 'iv', 'erm', 'measures', 'models', 'tools', 'v', 'erm', 'case', 'studies', 'vi', 'practical', 'considerations', 'implementing', 'erm', 'appendicesa', 'riskrelated', 'regulatory', 'rating', 'agency', 'corporate', 'governanceguidelines', 'requirements', 'b', 'continuum', 'risk', 'modeling', 'methods', 'c', 'erm', 'bibliography', 'overview', 'enterprise', 'risk', 'managementi', 'executive', 'summarythis', 'document', 'intended', 'primarily', 'risk', 'management', 'education', 'ofcandidates', 'membership', 'casualty', 'actuarial', 'society', 'cas', 'current', 'members', 'ofthe', 'cas', 'well', 'risk', 'management', 'professionals', 'also', 'find', 'material', 'ofinterestin', 'chapter', 'ii', 'evolution', 'rationale', 'enterprise', 'risk', 'management', 'erm', 'isexplained', 'erm', 'movement', 'driven', 'internal', 'eg', 'competitiveadvantage', 'external']\n"
     ]
    }
   ],
   "source": [
    "# Add words \"language\" and \"processing\" to to stop words\n",
    "add_stopwords = ['language','processing']\n",
    "new_stopwords_list = stop_words + add_stopwords\n",
    "\n",
    "# Removing \"most\" from stopwords\n",
    "delete_stopwords = {'most'} \n",
    "custom_stop_words = set([word for word in new_stopwords_list if word not in delete_stopwords])\n",
    "\n",
    "# Print without new stop words\n",
    "without_custom_stopword = [w for w in tokens if not w in custom_stop_words]\n",
    "print(without_custom_stopword[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc68ac7",
   "metadata": {},
   "source": [
    "### 7. Perform the part of speech tagging for the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9434d7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('overview', 'NN'), ('of', 'IN'), ('enterprise', 'NN'), ('risk', 'NN'), ('managementcasualty', 'NN'), ('actuarial', 'JJ'), ('societyenterprise', 'NN'), ('risk', 'NN'), ('management', 'NN'), ('committeemay', 'NN'), ('overview', 'NN'), ('of', 'IN'), ('enterprise', 'NN'), ('risk', 'NN'), ('managementtable', 'NN'), ('of', 'IN'), ('contentspagei', 'JJ'), ('executive', 'NN'), ('summary', 'NN'), ('ii', 'VBD'), ('the', 'DT'), ('erm', 'JJ'), ('evolution', 'NN'), ('iii', 'NN'), ('erm', 'JJ'), ('definition', 'NN'), ('and', 'CC'), ('conceptual', 'JJ'), ('framework', 'NN'), ('iv', 'JJ'), ('erm', 'JJ'), ('language', 'NN'), ('measures', 'NNS'), ('models', 'NNS'), ('and', 'CC'), ('tools', 'NNS'), ('v', 'VBP'), ('erm', 'JJ'), ('case', 'NN'), ('studies', 'NNS'), ('vi', 'VBP'), ('practical', 'JJ'), ('considerations', 'NNS'), ('in', 'IN'), ('implementing', 'VBG'), ('erm', 'JJ'), ('appendicesa', 'NN'), ('riskrelated', 'VBD'), ('regulatory', 'JJ'), ('rating', 'NN'), ('agency', 'NN'), ('and', 'CC'), ('corporate', 'JJ'), ('governanceguidelines', 'NNS'), ('and', 'CC'), ('requirements', 'NNS'), ('b', 'VBP'), ('a', 'DT'), ('continuum', 'NN'), ('of', 'IN'), ('risk', 'NN'), ('modeling', 'VBG'), ('methods', 'NNS'), ('c', 'JJ'), ('erm', 'JJ'), ('bibliography', 'NN'), ('overview', 'NN'), ('of', 'IN'), ('enterprise', 'NN'), ('risk', 'NN'), ('managementi', 'VBP'), ('executive', 'NN'), ('summarythis', 'NN'), ('document', 'NN'), ('is', 'VBZ'), ('intended', 'VBN'), ('primarily', 'RB'), ('to', 'TO'), ('further', 'VB'), ('the', 'DT'), ('risk', 'NN'), ('management', 'NN'), ('education', 'NN'), ('ofcandidates', 'VBZ'), ('for', 'IN'), ('membership', 'NN'), ('in', 'IN'), ('the', 'DT'), ('casualty', 'NN'), ('actuarial', 'JJ'), ('society', 'NN'), ('cas', 'NN'), ('current', 'JJ'), ('members', 'NNS'), ('ofthe', 'VBP'), ('cas', 'NN'), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('other', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "# Speech tagging the text and printing the first 100 words\n",
    "pos = nltk.pos_tag(tokens)\n",
    "print(pos[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cfdefa",
   "metadata": {},
   "source": [
    "### 8. Perform the named entities recognization for the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5a590ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = nltk.ne_chunk(pos, binary = True)\n",
    "for chunk in chunks:\n",
    "   if hasattr(chunk, 'label'):\n",
    "       print(' '.join(c[0] for c in chunk), chunk.label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7045ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
